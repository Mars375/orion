# Phase 4.1 Research: Go Redis Streams Implementation

**Date**: 2026-01-16
**Phase**: 4.1 - Technical Pivot: Bus Migration to Go
**Status**: Research Complete

---

## Executive Summary

This research evaluates the Go ecosystem for implementing a high-performance, type-safe Redis Streams event bus to replace the current Python implementation. The migration is critical for Phase 5 (AI Council) success, as multiple concurrent LLM inference calls will saturate CPU and memory on the Pi 5 (16GB total).

**Key Findings:**
- **Primary Redis Client**: `go-redis/v9` (official, mature, 58 Context7 code examples)
- **Alternative High-Performance Client**: `rueidis` (14x throughput in benchmarks, auto-pipelining)
- **JSON Schema Validation**: `kaptinlin/jsonschema` (JSON Schema Draft 2020-12, Dec 2025 release)
- **Code Generation**: `omissis/go-jsonschema` for generating Go structs from JSON Schema
- **Worker Pool Pattern**: Standard Go patterns with bounded concurrency and graceful shutdown

**Recommendation**: Start with `go-redis/v9` for stability and community support. Benchmark `rueidis` for Phase 5 if performance becomes critical.

---

## 1. Go Redis Client Libraries

### 1.1 go-redis/v9 (Primary Recommendation)

**Status**: Official Redis Go client, actively maintained
**Repository**: https://github.com/redis/go-redis
**Context7 Library ID**: /redis/go-redis
**Code Examples**: 58 snippets
**Source Reputation**: High
**Benchmark Score**: 92.7

**Strengths:**
- Official Redis client with broad adoption
- Comprehensive Redis Streams support: `XAdd`, `XReadGroup`, `XAck`, `XGroupCreate`
- Consumer group management with automatic creation (`XGroupCreateMkStream`)
- Built-in connection pooling (configurable via `PoolSize`, `MinIdleConns`, `MaxIdleConns`)
- Well-documented API with extensive community examples
- Stable API surface (v9 is current, breaking changes rare)

**Connection Pool Best Practices (2025):**
```go
redis.NewClient(&redis.Options{
    Addr:            "localhost:6379",
    PoolSize:        100,   // Max connections (default: 10 * CPU cores)
    MinIdleConns:    10,    // Reduce latency for bursty traffic
    MaxIdleConns:    50,    // Balance resource usage
    ConnMaxIdleTime: 5 * time.Minute,
    ConnMaxLifetime: 1 * time.Hour, // Rotate connections periodically
})
```

**Consumer Group Pattern:**
```go
// Create consumer group (idempotent)
err := rdb.XGroupCreateMkStream(ctx, "orion:events", "workers", "$").Err()
if err != nil && !strings.Contains(err.Error(), "BUSYGROUP") {
    log.Fatal(err)
}

// Read from consumer group
streams, err := rdb.XReadGroup(ctx, &redis.XReadGroupArgs{
    Group:    "workers",
    Consumer: "consumer1",
    Streams:  []string{"orion:events", ">"},  // ">" = undelivered messages
    Count:    10,
    Block:    0,  // Block indefinitely
}).Result()

// Process and acknowledge
for _, stream := range streams {
    for _, msg := range stream.Messages {
        // Process message...
        rdb.XAck(ctx, "orion:events", "workers", msg.ID)
    }
}
```

**Trade-offs:**
- Mature and stable, but not the fastest (rueidis has 14x higher throughput in benchmarks)
- No automatic pipelining (manual batching required for optimal performance)
- Higher memory footprint than rueidis

**Verdict**: **Recommended for initial implementation**. Proven stability, excellent documentation, and sufficient performance for Phase 4.1. Can migrate to rueidis later if Phase 5 benchmarks reveal bottlenecks.

---

### 1.2 rueidis (High-Performance Alternative)

**Status**: Official Redis Go client (newer, performance-focused)
**Repository**: https://github.com/redis/rueidis
**Latest Release**: December 29, 2025

**Strengths:**
- **14x higher throughput** than go-redis in local benchmarks (MacBook Pro M1, 64 parallelism)
- **Auto-pipelining by default**: All concurrent non-blocking commands automatically batched
- **Client-side caching**: 98% reduction in sec/op for cache hit scenarios
- **Lower allocations**: 100% reduction in B/op and allocs/op vs go-redis
- Built-in support for RedisJSON, RedisBloom, RediSearch

**Performance Gains:**
- Throughput: 92% reduction in sec/op vs go-redis baseline
- Memory: 99% reduction in B/op
- Allocations: 100% reduction in allocs/op

**Trade-offs:**
- Newer library with smaller community (less battle-tested)
- **Tail latency concerns**: Some users report p99 latency significantly higher than go-redis in production
- Auto-pipelining adds latency due to goroutine scheduling and head-of-line blocking
- Can disable auto-pipelining (`DisableAutoPipelining: true`) to trade throughput for latency

**Verdict**: **Consider for Phase 5 if go-redis becomes a bottleneck**. The 14x throughput gain is compelling for AI Council's high-concurrency dispatch, but tail latency risks require careful benchmarking in ORION's workload.

---

## 2. JSON Schema Validation in Go

### 2.1 kaptinlin/jsonschema (Primary Recommendation)

**Repository**: https://github.com/kaptinlin/jsonschema
**Latest Release**: December 14, 2025
**JSON Schema Support**: Draft 2020-12 (matches ORION's current schemas)

**Strengths:**
- **Full Draft 2020-12 compliance** (same draft as ORION contracts)
- **Direct struct validation**: Validate Go structs without JSON marshaling (zero-copy)
- **Internationalization support**: Multilingual error messages
- **Enhanced validation outputs**: Detailed error reporting for debugging
- **Recent development**: Active maintenance with 2025 releases

**Usage Pattern:**
```go
import "github.com/kaptinlin/jsonschema"

// Load schema from file
schema, err := jsonschema.NewCompiler().Compile("event.schema.json")
if err != nil {
    log.Fatal(err)
}

// Validate JSON
var event map[string]interface{}
json.Unmarshal(data, &event)
if err := schema.Validate(event); err != nil {
    // Handle validation errors
}
```

**Trade-offs:**
- Runtime validation (no compile-time guarantees)
- Schema loading at startup adds initialization time
- Validation performance overhead (mitigated by caching compiled schemas)

**Verdict**: **Recommended**. Best match for ORION's JSON Schema Draft 2020-12 contracts, with active maintenance and direct struct validation for performance.

---

### 2.2 Alternative: santhosh-tekuri/jsonschema/v6

**Repository**: https://github.com/santhosh-tekuri/jsonschema
**Latest Release**: May 23, 2025
**Imports**: 140 projects (high adoption)

**Strengths:**
- Mature library with broad adoption
- Supports multiple JSON Schema drafts (v4, v6, v7, 2019-09, 2020-12)
- Well-tested in production environments

**Trade-offs:**
- Less recent updates than kaptinlin/jsonschema
- No direct struct validation (requires JSON marshaling)

**Verdict**: **Fallback option** if kaptinlin/jsonschema has compatibility issues.

---

## 3. Code Generation: JSON Schema to Go Structs

### 3.1 omissis/go-jsonschema (Recommended)

**Repository**: https://github.com/omissis/go-jsonschema
**Status**: Most actively maintained fork (2025 blog posts reference it)

**Approach**: Generate Go structs from JSON Schema at build time

**Benefits:**
- **Compile-time type safety**: Eliminates entire classes of runtime errors
- **Performance**: No runtime validation overhead for struct fields
- **IDE support**: Full autocomplete and type checking
- **Reduced boilerplate**: Auto-generated struct tags for JSON marshaling

**Installation:**
```bash
go install github.com/atombender/go-jsonschema@latest
```

**Usage:**
```bash
go-jsonschema \
  --schema-package=contracts \
  --output=contracts/generated.go \
  bus/contracts/*.schema.json
```

**Generated Output Example:**
```go
// Generated from event.schema.json
type Event struct {
    Version   string    `json:"version"`
    EventID   string    `json:"event_id"`
    Timestamp time.Time `json:"timestamp"`
    Source    string    `json:"source"`
    EventType string    `json:"event_type"`
    Severity  string    `json:"severity"`
    Data      EventData `json:"data"`
}
```

**Trade-offs:**
- **Build-time dependency**: Schemas must be generated before compilation
- **Version drift risk**: Generated code can become stale if schemas change
- **Loss of dynamic validation**: Cannot validate arbitrary JSON against schemas at runtime

**Recommendation**: **Hybrid approach**:
1. **Generate structs for known contract types** (event, incident, decision, etc.) → compile-time safety
2. **Keep runtime validation for boundary validation** → defense-in-depth

This provides:
- Type safety for internal Go code (compiler catches contract violations)
- Runtime validation for external inputs (Redis Streams, MQTT, APIs)
- Best of both worlds: performance + safety

---

### 3.2 Alternative: elastic/go-json-schema-generate

**Repository**: https://github.com/elastic/go-json-schema-generate
**Status**: Maintained by Elastic, customized for fleet-server

**Verdict**: Specialized for Elastic use cases. Use `omissis/go-jsonschema` for broader JSON Schema support.

---

## 4. High-Performance Patterns

### 4.1 Worker Pool Pattern (Bounded Concurrency)

**Problem**: Unbounded goroutine creation can exhaust memory and cause CPU thrashing.

**Solution**: Fixed-size worker pool with task queue.

**Pattern (2025 Best Practice):**
```go
func workerPool(ctx context.Context, jobs <-chan Job, numWorkers int, wg *sync.WaitGroup) {
    for i := 0; i < numWorkers; i++ {
        wg.Add(1)
        go func(workerID int) {
            defer wg.Done()
            for {
                select {
                case job, ok := <-jobs:
                    if !ok {
                        return // Channel closed, exit
                    }
                    processJob(job)
                case <-ctx.Done():
                    return // Graceful shutdown
                }
            }
        }(i)
    }
}
```

**Benefits:**
- **Predictable resource usage**: Fixed number of goroutines
- **Backpressure**: Bounded job queue prevents memory exhaustion
- **Graceful shutdown**: Context cancellation propagates to all workers

**Library Option**: `alitto/pond` (minimalistic, high-performance worker pool)
- Repository: https://github.com/alitto/pond
- Features: Worker pool, task submission, graceful shutdown
- Trade-off: Adds dependency vs standard library pattern

**Recommendation**: **Use standard library pattern** (above) to minimize dependencies. Consider `pond` only if complex task scheduling (priorities, retries) is needed.

---

### 4.2 Graceful Shutdown (2025-2026 Best Practices)

**Problem**: Kubernetes sends SIGTERM and waits for `terminationGracePeriodSeconds` (default: 30s). If shutdown doesn't complete, SIGKILL forces termination, potentially losing in-flight messages.

**Solution**: `signal.NotifyContext` with timeout for resource cleanup.

**Pattern:**
```go
func main() {
    // Create context that cancels on SIGTERM/SIGINT
    ctx, stop := signal.NotifyContext(context.Background(), os.Interrupt, syscall.SIGTERM)
    defer stop()

    // Start services
    var wg sync.WaitGroup
    wg.Add(1)
    go func() {
        defer wg.Done()
        runEventBus(ctx) // Blocks until ctx cancelled
    }()

    // Wait for shutdown signal
    <-ctx.Done()
    log.Println("Received shutdown signal, draining in-flight messages...")

    // Create shutdown timeout context (e.g., 25s to stay under K8s 30s limit)
    shutdownCtx, cancel := context.WithTimeout(context.Background(), 25*time.Second)
    defer cancel()

    // Wait for workers to finish with timeout
    done := make(chan struct{})
    go func() {
        wg.Wait()
        close(done)
    }()

    select {
    case <-done:
        log.Println("Graceful shutdown complete")
    case <-shutdownCtx.Done():
        log.Println("Shutdown timeout exceeded, forcing exit")
    }

    // Clean up resources (Redis connections, etc.)
    cleanup()
}
```

**Key Principles (2025-2026):**
1. **Use `signal.NotifyContext`** (preferred over manual `signal.Notify` + channels)
2. **Shutdown timeout < terminationGracePeriodSeconds** (e.g., 25s for K8s 30s default)
3. **Delay resource cleanup until workers finish** (critical resources like Redis may be needed by in-flight handlers)
4. **Propagate cancellation via context** (all goroutines check `ctx.Done()`)

---

### 4.3 Connection Pooling (Redis)

**go-redis Configuration:**
```go
redis.NewClient(&redis.Options{
    Addr:            "localhost:6379",

    // Connection pool sizing
    PoolSize:        100,  // Max connections (default: 10 * runtime.GOMAXPROCS)
    MinIdleConns:    10,   // Pre-warmed connections (reduces latency spikes)
    MaxIdleConns:    50,   // Limit idle connections (balance latency vs resources)

    // Connection lifecycle
    ConnMaxIdleTime: 5 * time.Minute,  // Close idle connections after 5m
    ConnMaxLifetime: 1 * time.Hour,     // Rotate long-lived connections

    // Timeouts
    DialTimeout:  5 * time.Second,
    ReadTimeout:  3 * time.Second,
    WriteTimeout: 3 * time.Second,
})
```

**Rationale:**
- **PoolSize: 100** → Handles high concurrency (Phase 5 AI Council will dispatch many concurrent events)
- **MinIdleConns: 10** → Reduces latency for bursty traffic (pre-warmed connections)
- **ConnMaxIdleTime: 5m** → Prevents resource leaks from idle connections
- **ConnMaxLifetime: 1h** → Prevents stale connection issues (network glitches, Redis restarts)

---

## 5. Migration Strategy

### 5.1 Backward Compatibility Requirements

**Constraint**: Existing Python modules (guardian, brain, commander, memory, approval) must continue working during migration.

**Approach**: Run Go bus alongside Python bus with gradual cutover.

**Phase 1: Parallel Operation**
```
┌─────────────┐
│   Python    │───┐
│   Publishers│   │    ┌──────────────┐
└─────────────┘   ├───→│  Redis       │
                  │    │  Streams     │
┌─────────────┐   │    └──────────────┘
│   Go Bus    │───┘           │
│  (Observer) │                │
└─────────────┘                ↓
                        ┌──────────────┐
                        │  Python      │
                        │  Consumers   │
                        └──────────────┘
```

**Phase 2: Consumer Migration**
```
┌─────────────┐
│   Python    │────→ Redis Streams
│   Publishers│
└─────────────┘           │
                          ↓
                    ┌──────────────┐
                    │  Go Bus      │
                    │  Consumers   │
                    └──────────────┘
```

**Phase 3: Full Cutover**
```
┌─────────────┐
│   Go Bus    │────→ Redis Streams
│  (Publisher)│
└─────────────┘           │
                          ↓
                    ┌──────────────┐
                    │  Go Bus      │
                    │  Consumers   │
                    └──────────────┘
```

---

### 5.2 Contract Validation Strategy

**Dual Validation Approach** (defense-in-depth):

1. **Compile-Time (Generated Structs)**:
   ```go
   // Generated from event.schema.json
   type Event struct { ... }

   // Type system enforces contract
   func (b *Bus) PublishEvent(ctx context.Context, event Event) error {
       // Compiler guarantees Event matches schema structure
   }
   ```

2. **Runtime (JSON Schema Validation)**:
   ```go
   // Validate incoming JSON from Redis Streams
   func (b *Bus) validateIncoming(data []byte, schemaName string) error {
       schema := b.validator.GetSchema(schemaName)
       return schema.Validate(data)
   }
   ```

**Rationale**:
- **Internal Go code**: Use generated structs (compile-time safety, zero runtime overhead)
- **External inputs** (Redis, MQTT, APIs): Use runtime validation (untrusted sources)
- **Contract changes**: Regenerate structs + bump schema version (backward compatibility)

---

### 5.3 Testing Strategy

**Unit Tests**:
- Contract validation (valid/invalid messages)
- Worker pool (bounded concurrency, graceful shutdown)
- Connection pool (lifecycle, error handling)

**Integration Tests**:
- Redis Streams publish/consume roundtrip
- Consumer group creation (idempotency)
- Message acknowledgment (XAck)
- Graceful shutdown (in-flight message completion)

**Migration Tests**:
- Python publisher → Go consumer (backward compatibility)
- Go publisher → Python consumer (forward compatibility)
- Parallel operation (no message loss, no duplication)

**Performance Benchmarks**:
- Throughput (messages/sec)
- Latency (p50, p95, p99)
- Memory footprint (RSS under sustained load)
- CPU usage (under high concurrency)

---

## 6. Performance Targets

### 6.1 Phase 4.1 Targets (Event Bus Baseline)

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Throughput** | 1,000 msg/sec | Current load is ~10 msg/sec. 100x headroom for AI Council |
| **Latency (p95)** | < 10ms | Low enough to not bottleneck decision loop |
| **Latency (p99)** | < 50ms | Tail latency acceptable for non-critical path |
| **Memory (RSS)** | < 100MB | Leave 15.9GB for LLMs on Pi 5 (16GB total) |
| **CPU (sustained)** | < 10% | Leave CPU for guardian/brain/AI Council |

---

### 6.2 Phase 5 Targets (AI Council Load)

| Metric | Target | Rationale |
|--------|--------|-----------|
| **Throughput** | 5,000 msg/sec | Multiple AI models polling decisions + reasoning events |
| **Latency (p95)** | < 10ms | Fast event dispatch for real-time AI reasoning |
| **Concurrent Consumers** | 20+ | Guardian (3 models) + Brain (3 models) + Memory (embeddings) |
| **Memory (RSS)** | < 50MB | Aggressive constraint (LLMs are memory-hungry) |

---

## 7. Recommended Architecture

### 7.1 Module Structure

```
bus/go/
├── cmd/
│   └── orion-bus/
│       └── main.go              # Entry point (service daemon)
├── internal/
│   ├── bus/
│   │   ├── bus.go               # EventBus implementation
│   │   ├── publisher.go         # Publishing logic
│   │   ├── consumer.go          # Consumer group logic
│   │   └── bus_test.go          # Unit tests
│   ├── validator/
│   │   ├── validator.go         # JSON Schema runtime validation
│   │   └── validator_test.go
│   ├── pool/
│   │   ├── worker.go            # Worker pool pattern
│   │   └── worker_test.go
│   └── shutdown/
│       ├── shutdown.go          # Graceful shutdown coordinator
│       └── shutdown_test.go
├── pkg/
│   └── contracts/
│       ├── generated.go         # Generated structs (from go-jsonschema)
│       └── contracts_test.go
├── go.mod
├── go.sum
└── README.md
```

---

### 7.2 Dependencies

```go
// go.mod
module github.com/orion/bus

go 1.22

require (
    github.com/redis/go-redis/v9 v9.7.0          // Redis client
    github.com/kaptinlin/jsonschema v1.0.0        // JSON Schema validation
    github.com/google/uuid v1.6.0                 // UUID generation (events)
    github.com/stretchr/testify v1.9.0            // Testing assertions
)
```

**Why These Dependencies?**
- **go-redis/v9**: Official, mature, well-documented
- **kaptinlin/jsonschema**: Draft 2020-12 support (matches ORION contracts)
- **google/uuid**: Standard UUID library (event_id generation)
- **testify**: Industry-standard testing library (assertions, mocking)

**Avoided Dependencies:**
- Worker pool libraries (standard library pattern sufficient)
- Logging frameworks (use `log/slog` from Go 1.21+)
- Metrics libraries (defer to Phase 2 Prometheus integration)

---

## 8. Open Questions & Risks

### 8.1 Open Questions

1. **Contract versioning in Go**:
   - How to handle schema version bumps? Regenerate structs with version suffix (`EventV1`, `EventV2`)?
   - Backward compatibility: Support multiple schema versions simultaneously?

2. **Consumer offset management**:
   - Current Python bus uses `>` (undelivered messages). Should Go bus support replay from arbitrary offset?
   - Consumer group state: Should we persist last-read offset externally (e.g., in Redis hash)?

3. **Monitoring integration**:
   - Prometheus metrics: Should we add instrumentation in Phase 4.1 or defer to Phase 2?
   - Metrics to track: message throughput, validation errors, consumer lag, worker pool utilization

4. **Error handling for poison messages**:
   - Current Python bus acknowledges failed messages to prevent blocking. Keep same behavior in Go?
   - Add dead-letter queue for debugging? (Separate Redis stream for failed messages)

---

### 8.2 Risks

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **Tail latency regression (rueidis)** | Medium | High | Start with go-redis, benchmark rueidis in Phase 5 |
| **Contract version drift (generated structs)** | Medium | Medium | Automated tests for schema → struct generation |
| **Migration downtime** | Low | High | Parallel operation with cutover validation |
| **Memory leak (connection pool)** | Low | Critical | Integration tests with sustained load + profiling |
| **Consumer group state corruption** | Low | High | Redis cluster with replication, consumer group recovery logic |

---

## 9. Conclusion

### 9.1 Recommended Stack

| Component | Library | Justification |
|-----------|---------|---------------|
| **Redis Client** | `go-redis/v9` | Official, mature, 58 Context7 examples. Sufficient performance for Phase 4.1. |
| **JSON Schema Validation** | `kaptinlin/jsonschema` | Draft 2020-12 support, direct struct validation, Dec 2025 release |
| **Code Generation** | `omissis/go-jsonschema` | Generate Go structs from JSON Schema for compile-time safety |
| **Worker Pool** | Standard library pattern | No external dependency, sufficient for bounded concurrency |
| **Graceful Shutdown** | `signal.NotifyContext` | Modern Go 1.16+ pattern, clean cancellation propagation |

---

### 9.2 Next Steps

1. **Phase 4.1 Planning** (`/gsd:plan-phase 4.1`):
   - Break down implementation into execution plans (PLAN.md)
   - Define milestones: (1) Core bus, (2) Contract validation, (3) Migration, (4) Benchmarks

2. **Prototype** (First Plan):
   - Implement minimal Go bus with go-redis + kaptinlin/jsonschema
   - Validate publish/consume roundtrip
   - Measure baseline performance

3. **Contract Generation** (Second Plan):
   - Set up go-jsonschema tooling in CI/CD
   - Generate structs from existing schemas
   - Integration tests for Python ↔ Go interop

4. **Migration** (Third Plan):
   - Run Go bus in observer mode (parallel with Python)
   - Cutover consumers one module at a time
   - Burn-in period (1 week) before removing Python bus

---

## Sources

### Go Redis Streams
- [Redis Streams | Docs](https://redis.io/docs/latest/develop/data-types/streams/)
- [Real-time with Redis Streams in Go - DEV Community](https://dev.to/lovestaco/real-time-with-redis-streams-in-go-1hlh)
- [Watermill Redis Stream | Event-Driven in Go](https://watermill.io/pubsubs/redisstream/)
- [redis package - go-redis/v9](https://pkg.go.dev/github.com/go-redis/redis/v8)

### JSON Schema Validation
- [GitHub - kaptinlin/jsonschema](https://github.com/kaptinlin/jsonschema)
- [jsonschema package - kaptinlin/jsonschema](https://pkg.go.dev/github.com/kaptinlin/jsonschema)
- [GitHub - santhosh-tekuri/jsonschema/v6](https://github.com/santhosh-tekuri/jsonschema)
- [GitHub - xeipuuv/gojsonschema](https://github.com/xeipuuv/gojsonschema)

### High-Performance Patterns
- [GitHub - redis/rueidis](https://github.com/redis/rueidis)
- [Build Production-Ready Distributed Task Queue with Go, Redis, and Advanced Goroutine Patterns](https://golang.elitedev.in/golang/build-production-ready-distributed-task-queue-with-go-redis-and-advanced-goroutine-patterns-18573a8b/)
- [Connection pools and multiplexing | Docs](https://redis.io/docs/latest/develop/clients/pools-and-muxing/)
- [How to Use Redis in Go with go-redis](https://oneuptime.com/blog/post/2026-01-07-go-redis/view)

### Worker Pool & Graceful Shutdown
- [7 Powerful Golang Concurrency Patterns That Will Transform Your Code in 2025](https://cristiancurteanu.com/7-powerful-golang-concurrency-patterns-that-will-transform-your-code-in-2025/)
- [Go Worker Pools: Concurrency That Doesn't Burn Your Kitchen Down - DEV Community](https://dev.to/jones_charles_ad50858dbc0/go-worker-pools-concurrency-that-doesnt-burn-your-kitchen-down-59oo)
- [GitHub - alitto/pond](https://github.com/alitto/pond)
- [Building Resilient Go Services: Context, Graceful Shutdown, and Retry/Timeout Patterns](https://medium.com/@serifcolakel/building-resilient-go-services-context-graceful-shutdown-and-retry-timeout-patterns-041eea332162)
- [Graceful Shutdown in Go, Explained: Signals, Contexts, and the Correct Shutdown Sequence](https://rafalroppel.medium.com/graceful-shutdown-in-go-explained-signals-contexts-and-the-correct-shutdown-sequence-f24fd9ef8fac)
- [Implementing Graceful Shutdown in Go | RudderStack Blog](https://www.rudderstack.com/blog/implementing-graceful-shutdown-in-go/)

### Code Generation
- [Generating Go code from JSON Schema documents · Jamie Tanna](https://www.jvt.me/posts/2025/06/05/json-schema-go/)
- [GitHub - omissis/go-jsonschema](https://github.com/omissis/go-jsonschema)
- [GitHub - a-h/generate](https://github.com/a-h/generate)
- [GitHub - elastic/go-json-schema-generate](https://github.com/elastic/go-json-schema-generate)
