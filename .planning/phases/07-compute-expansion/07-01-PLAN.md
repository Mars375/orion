---
phase: 07-compute-expansion
plan: 01
type: execute
depends_on: []
files_modified: [core/inference/worker/agent.go, core/inference/worker/metrics.go, core/inference/worker/registry.go, core/inference/contracts/inference.go]
---

<objective>
Implement inference worker agent that wraps Ollama and reports health metrics to Redis.

Purpose: Workers run on Pi nodes (8GB, 16GB) and handle LLM inference requests. Each worker publishes health metrics (CPU, RAM, temperature, loaded models) to enable intelligent routing.
Output: Working worker agent binary that connects to Redis, publishes health, and exposes an inference endpoint.
</objective>

<execution_context>
~/.claude/get-shit-done/workflows/execute-plan.md
./summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/phases/07-compute-expansion/07-CONTEXT.md
@.planning/phases/07-compute-expansion/07-RESEARCH.md
@.planning/phases/06-edge-integration/06-04-SUMMARY.md
@edge/internal/client/redis.go

**Tech stack (from RESEARCH.md):**
- github.com/ollama/ollama/api - Official Go client for Ollama
- github.com/redis/go-redis/v9 - Already used in orion-bus and orion-edge
- github.com/shirou/gopsutil/v4 - System health metrics (CPU, RAM, temp)

**Patterns from Phase 6:**
- Redis client wrapper pattern (edge/internal/client/redis.go)
- Health reporting via periodic goroutine
- Graceful shutdown with context cancellation

**Don't hand-roll (from RESEARCH.md):**
- Ollama API client (use github.com/ollama/ollama/api)
- System metrics (use gopsutil)
- Model memory management (use Ollama's keep_alive + OLLAMA_MAX_LOADED_MODELS)

**Hardware constraints:**
- Pi 16GB: Primary validator + Orchestrator
- Pi 8GB: Dedicated to heavy LLM analysis
- Pi 4GB: EXCLUDED from LLM tasks (kinematics only)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create inference contracts and Go module</name>
  <files>core/inference/go.mod, core/inference/contracts/inference.go</files>
  <action>
Create Go module for inference subsystem and define data contracts:

1. Create core/inference/ directory structure:
   - core/inference/go.mod (module, Go 1.22+)
   - core/inference/contracts/inference.go (shared types)

2. Define InferenceRequest type:
   - RequestID string (UUID)
   - Model string (e.g., "gemma3:1b", "llama3.2:3b")
   - Messages []Message (role: user/assistant/system, content: string)
   - KeepAlive time.Duration (model residency, default 10 minutes)
   - Callback string (response stream name)

3. Define InferenceResponse type:
   - RequestID string
   - Model string
   - Response string (generated content)
   - PromptTokens int
   - CompletionTokens int
   - LoadDurationMs int64 (0 if model was resident)
   - TotalDurationMs int64
   - Error string (empty if success)

4. Define NodeHealth type:
   - NodeID string
   - CPUPercent float64
   - RAMPercent float64
   - RAMUsedMB int64
   - RAMTotalMB int64
   - TempCelsius float64
   - Models []string (currently loaded models)
   - Available bool
   - LastSeen time.Time

5. Add dependencies to go.mod:
   - github.com/ollama/ollama/api
   - github.com/redis/go-redis/v9
   - github.com/shirou/gopsutil/v4

Run `go mod tidy` to fetch dependencies.
  </action>
  <verify>go build ./... succeeds in core/inference/, go mod tidy produces clean go.sum</verify>
  <done>Go module created with all contract types defined, dependencies resolved</done>
</task>

<task type="auto">
  <name>Task 2: Implement health metrics collector using gopsutil</name>
  <files>core/inference/worker/metrics.go, core/inference/worker/metrics_test.go</files>
  <action>
Create metrics collector that gathers system health for routing decisions:

1. Create HealthCollector struct:
   - Fields: nodeID string, ollamaHost string
   - Constructor: NewHealthCollector(nodeID, ollamaHost string)

2. Implement CollectHealth() (NodeHealth, error):
   - CPU: cpu.Percent(time.Second, false) - returns []float64, use first element
   - Memory: mem.VirtualMemory() - use UsedPercent, Used/1024/1024 for MB, Total/1024/1024
   - Temperature: host.SensorsTemperatures() - find "cpu_thermal" or "cpu-thermal" sensor
     - If not found, fallback to reading /sys/class/thermal/thermal_zone0/temp and dividing by 1000
     - If still not found, return 0 (optional metric)
   - Models: Query Ollama /api/ps endpoint to get currently loaded models

3. Implement getLoadedModels() ([]string, error):
   - Use ollama/api client: client.List(ctx) returns running models
   - Extract model names from response
   - Return empty slice if Ollama unreachable (don't fail health collection)

4. Implement IsAvailable() bool:
   - Return false if TempCelsius > 75
   - Return false if RAMPercent > 90
   - Return true otherwise

5. Write unit tests:
   - Test CPU/RAM collection (actual system values, just verify non-error)
   - Test temperature fallback logic
   - Test IsAvailable thresholds

AVOID: Reading /proc manually (use gopsutil). Don't fail health collection if Ollama is temporarily unreachable.
  </action>
  <verify>go test ./worker/... passes, HealthCollector.CollectHealth() returns valid NodeHealth</verify>
  <done>HealthCollector implemented with CPU, RAM, temperature, model list collection; IsAvailable respects thresholds</done>
</task>

<task type="auto">
  <name>Task 3: Implement Redis health registry publisher</name>
  <files>core/inference/worker/registry.go, core/inference/worker/registry_test.go</files>
  <action>
Create Redis-based health registry for publishing worker status:

1. Create HealthRegistry struct:
   - Fields: redis *redis.Client, nodeID string, keyPrefix string
   - Constructor: NewHealthRegistry(redis *redis.Client, nodeID, keyPrefix string)

2. Implement PublishHealth(ctx context.Context, health NodeHealth) error:
   - Serialize health to JSON
   - Use HSET to update hash field: redis.HSet(ctx, "orion:inference:health", nodeID, jsonData)
   - Set TTL on individual field not supported by Redis, so use separate key with SETEX as backup:
     - redis.SetEx(ctx, "orion:inference:health:"+nodeID, jsonData, 30*time.Second)
   - Log success at DEBUG level

3. Implement GetAllHealth(ctx context.Context) ([]NodeHealth, error):
   - Use HGETALL: redis.HGetAll(ctx, "orion:inference:health")
   - Filter by last_seen > 15 seconds ago (stale entries)
   - Unmarshal each entry to NodeHealth
   - Return slice of healthy nodes

4. Implement RemoveNode(ctx context.Context) error:
   - HDEL to remove from hash
   - Used during graceful shutdown

5. Write unit tests using miniredis:
   - Test PublishHealth writes correct JSON structure
   - Test GetAllHealth returns multiple nodes
   - Test stale node filtering (mock last_seen in past)
   - Test RemoveNode cleans up

Pattern from edge/internal/client/redis.go: Use go-redis with connection pool, handle errors gracefully.
  </action>
  <verify>go test ./worker/... -v passes all registry tests, miniredis validates Redis operations</verify>
  <done>HealthRegistry implemented with publish, get, and remove operations; unit tests passing</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `go build ./...` succeeds in core/inference/
- [ ] `go test ./...` passes all tests in core/inference/
- [ ] `go mod tidy` produces no changes (deps clean)
- [ ] Contract types (InferenceRequest, InferenceResponse, NodeHealth) defined
- [ ] HealthCollector gathers CPU, RAM, temp, and model list
- [ ] HealthRegistry publishes to Redis hash with proper JSON structure
</verification>

<success_criteria>
- All tasks completed
- All verification checks pass
- Go module compiles without errors
- Unit tests provide coverage for metrics and registry
- Types follow patterns from RESEARCH.md
</success_criteria>

<output>
After completion, create `.planning/phases/07-compute-expansion/07-01-SUMMARY.md`:

# Phase 7 Plan 01: Worker Agent Foundation Summary

**[Substantive one-liner describing what shipped]**

## Accomplishments

- [Key outcome 1]
- [Key outcome 2]

## Files Created/Modified

- `path/to/file.go` - Description

## Decisions Made

[Key decisions and rationale, or "None"]

## Issues Encountered

[Problems and resolutions, or "None"]

## Next Step

Ready for 07-02-PLAN.md (Router Service)
</output>
